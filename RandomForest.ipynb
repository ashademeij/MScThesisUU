{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdey4v92m9OL"
      },
      "source": [
        "\n",
        "\n",
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gm1R8_wcm9ON"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WyLtM-OSokWP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/sample_data/final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vojy-s6rm9OS"
      },
      "outputs": [],
      "source": [
        "features = ['gender', 'RACE_Asian', 'RACE_Black/African American',\n",
        "            'RACE_Hispanic/Latino', 'RACE_Other', 'RACE_White', 'age_18-24',\n",
        "            'age_25-44', 'age_45-64', 'age_65-88',\n",
        "            'age_89+', 'previous_stays', 'prev_los_avg', 'Anion Gap',\n",
        "            'Bicarbonate', 'Chloride', 'Creatinine', 'Glucose', 'Hematocrit',\n",
        "            'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Platelet Count',\n",
        "            'Potassium', 'RDW', 'Red Blood Cells', 'Sodium', 'Urea Nitrogen',\n",
        "            'White Blood Cells', 'prescrip_count', 'diagnoses_num',\n",
        "            'ADM_Emergency', 'ADM_Other', 'ADM_Referral', 'ADM_Transfer',\n",
        "            'INS_Medicaid', 'INS_Medicare', 'INS_Other']\n",
        "\n",
        "\n",
        "X = df[features]\n",
        "y = df['los_category']\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6It0Q_WRm9OS",
        "outputId": "cbeeb399-a40f-4d86-928a-0154d851d10a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
            "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n",
            "/Users/ashademeij/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=100; total time=   5.2s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=100; total time=   6.4s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=100; total time=   7.2s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=200; total time=  10.3s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=200; total time=  13.1s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=200; total time=  13.8s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=100; total time=   8.1s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=100; total time=   7.7s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=100; total time=   6.1s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=200; total time=  12.4s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=200; total time=  15.9s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=200; total time=  16.6s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=500; total time=  26.2s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=500; total time=  33.3s\n",
            "[CV] END ....max_depth=3, max_features=0.6, n_estimators=500; total time=  35.0s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=100; total time=   7.0s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=100; total time=   9.2s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=100; total time=   9.5s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=200; total time=  18.0s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=200; total time=  13.1s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=200; total time=  17.1s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=500; total time=  38.5s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=500; total time=  40.9s\n",
            "[CV] END ....max_depth=3, max_features=0.7, n_estimators=500; total time=  29.4s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=100; total time=  12.1s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=100; total time=  12.9s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=100; total time=  10.3s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=200; total time=  24.6s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=500; total time=  42.2s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=200; total time=  25.5s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=500; total time=  44.9s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=200; total time=  20.5s\n",
            "[CV] END ....max_depth=3, max_features=0.8, n_estimators=500; total time=  33.5s\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=100; total time=  14.5s\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=100; total time=  12.3s\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=100; total time=  15.1s\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=200; total time=  29.0s\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=200; total time=  29.8s\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=200; total time=  24.2s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=500; total time= 1.0min\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=500; total time= 1.1min\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=100; total time=  16.9s\n",
            "[CV] END ....max_depth=6, max_features=0.6, n_estimators=500; total time=  51.3s\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=100; total time=  15.1s\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=100; total time=  12.7s\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=200; total time=  25.7s\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=200; total time=  31.6s\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=200; total time=  31.1s\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=500; total time= 1.2min\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=500; total time= 1.2min\n",
            "[CV] END ....max_depth=6, max_features=0.7, n_estimators=500; total time=  56.7s\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=100; total time=  17.0s\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=100; total time=  17.1s\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=100; total time=  15.3s\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=200; total time=  34.7s\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=200; total time=  34.5s\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=200; total time=  30.4s\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=500; total time= 1.4min\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=500; total time= 1.3min\n",
            "[CV] END ....max_depth=6, max_features=0.8, n_estimators=500; total time= 1.1min\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=100; total time=  20.1s\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=100; total time=  19.3s\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=100; total time=  17.5s\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=200; total time=  40.6s\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=200; total time=  36.5s\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=200; total time=  40.6s\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=500; total time= 1.4min\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=500; total time= 1.5min\n",
            "[CV] END ....max_depth=9, max_features=0.6, n_estimators=500; total time= 1.3min\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=100; total time=  22.2s\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=100; total time=  21.4s\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=100; total time=  19.3s\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=200; total time=  44.7s\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=200; total time=  40.2s\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=200; total time=  44.5s\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=500; total time= 1.7min\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=500; total time= 1.6min\n",
            "[CV] END ....max_depth=9, max_features=0.7, n_estimators=500; total time= 1.4min\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=500; total time= 1.5min\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=500; total time= 1.5min\n",
            "[CV] END ....max_depth=9, max_features=0.8, n_estimators=500; total time= 1.2min\n",
            "Best parameters found: {'max_depth': 9, 'max_features': 0.8, 'n_estimators': 500}\n",
            "Overall Accuracy of Random Forest Classifier: 0.6650971870095376\n",
            "Overall Confusion Matrix:\n",
            "[[1308 1736]\n",
            " [1038 4201]]\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.43      0.49      3044\n",
            "           1       0.71      0.80      0.75      5239\n",
            "\n",
            "    accuracy                           0.67      8283\n",
            "   macro avg       0.63      0.62      0.62      8283\n",
            "weighted avg       0.65      0.67      0.65      8283\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_features': [0.6, 0.7, 0.8]\n",
        "}\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Overall Accuracy of Random Forest Classifier:\", accuracy)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"Overall Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_encoded)\n",
        "\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_rf)\n",
        "\n",
        "class_report_labels = classification_report(y_test_labels, y_pred_labels)\n",
        "print(\"Overall Classification Report:\")\n",
        "print(class_report_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEQoactEm9OT",
        "outputId": "0807e06b-05a4-467f-9964-c6cd72f0c6ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MALE\n",
            "Accuracy for gender=0: 0.6596942880128721\n",
            "Confusion Matrix for gender=0:\n",
            "[[ 607  750]\n",
            " [ 519 1853]]\n",
            "Classification Report for gender=0:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.45      0.49      1357\n",
            "           1       0.71      0.78      0.74      2372\n",
            "\n",
            "    accuracy                           0.66      3729\n",
            "   macro avg       0.63      0.61      0.62      3729\n",
            "weighted avg       0.65      0.66      0.65      3729\n",
            "\n",
            "\n",
            "FEMALE\n",
            "Accuracy for gender=1: 0.6695212999560826\n",
            "Confusion Matrix for gender=1:\n",
            "[[ 701  986]\n",
            " [ 519 2348]]\n",
            "Classification Report for gender=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.42      0.48      1687\n",
            "           1       0.70      0.82      0.76      2867\n",
            "\n",
            "    accuracy                           0.67      4554\n",
            "   macro avg       0.64      0.62      0.62      4554\n",
            "weighted avg       0.66      0.67      0.66      4554\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate_subgroup(subgroup_name, subgroup_value):\n",
        "    subgroup_indices = X_test[subgroup_name] == subgroup_value\n",
        "    subgroup_X_test = X_test[subgroup_indices]\n",
        "    subgroup_y_test = y_test[subgroup_indices]\n",
        "    subgroup_y_pred = y_pred_rf[subgroup_indices]\n",
        "\n",
        "    accuracy = accuracy_score(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Accuracy for {subgroup_name}={subgroup_value}: {accuracy}\")\n",
        "\n",
        "    conf_matrix = confusion_matrix(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Confusion Matrix for {subgroup_name}={subgroup_value}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    subgroup_y_test_labels = label_encoder.inverse_transform(subgroup_y_test)\n",
        "    subgroup_y_pred_labels = label_encoder.inverse_transform(subgroup_y_pred)\n",
        "    class_report = classification_report(subgroup_y_test_labels, subgroup_y_pred_labels)\n",
        "    print(f\"Classification Report for {subgroup_name}={subgroup_value}:\")\n",
        "    print(class_report)\n",
        "\n",
        "# gender\n",
        "print(\"MALE\")\n",
        "evaluate_subgroup('gender', 0)\n",
        "print(\"\\nFEMALE\")\n",
        "evaluate_subgroup('gender', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUacsQxem9OT",
        "outputId": "d9bb282a-8ae8-4b8b-cce5-161021d54741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ASIAN\n",
            "Accuracy for RACE_Asian=1: 0.6982456140350877\n",
            "Confusion Matrix for RACE_Asian=1:\n",
            "[[ 42  65]\n",
            " [ 21 157]]\n",
            "Classification Report for RACE_Asian=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.39      0.49       107\n",
            "           1       0.71      0.88      0.79       178\n",
            "\n",
            "    accuracy                           0.70       285\n",
            "   macro avg       0.69      0.64      0.64       285\n",
            "weighted avg       0.69      0.70      0.68       285\n",
            "\n",
            "\n",
            "BLACK/AFRICAN AMERICAN\n",
            "Accuracy for RACE_Black/African American=1: 0.6802030456852792\n",
            "Confusion Matrix for RACE_Black/African American=1:\n",
            "[[138 207]\n",
            " [108 532]]\n",
            "Classification Report for RACE_Black/African American=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.40      0.47       345\n",
            "           1       0.72      0.83      0.77       640\n",
            "\n",
            "    accuracy                           0.68       985\n",
            "   macro avg       0.64      0.62      0.62       985\n",
            "weighted avg       0.66      0.68      0.66       985\n",
            "\n",
            "\n",
            "HISPANIC/LATINO\n",
            "Accuracy for RACE_Hispanic/Latino=1: 0.672972972972973\n",
            "Confusion Matrix for RACE_Hispanic/Latino=1:\n",
            "[[ 58  82]\n",
            " [ 39 191]]\n",
            "Classification Report for RACE_Hispanic/Latino=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.41      0.49       140\n",
            "           1       0.70      0.83      0.76       230\n",
            "\n",
            "    accuracy                           0.67       370\n",
            "   macro avg       0.65      0.62      0.62       370\n",
            "weighted avg       0.66      0.67      0.66       370\n",
            "\n",
            "\n",
            "OTHER RACE\n",
            "Accuracy for RACE_Other=1: 0.6557377049180327\n",
            "Confusion Matrix for RACE_Other=1:\n",
            "[[ 46  95]\n",
            " [ 52 234]]\n",
            "Classification Report for RACE_Other=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.33      0.38       141\n",
            "           1       0.71      0.82      0.76       286\n",
            "\n",
            "    accuracy                           0.66       427\n",
            "   macro avg       0.59      0.57      0.57       427\n",
            "weighted avg       0.63      0.66      0.64       427\n",
            "\n",
            "\n",
            "WHITE\n",
            "Accuracy for RACE_White=1: 0.6613577863577863\n",
            "Confusion Matrix for RACE_White=1:\n",
            "[[1024 1287]\n",
            " [ 818 3087]]\n",
            "Classification Report for RACE_White=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.44      0.49      2311\n",
            "           1       0.71      0.79      0.75      3905\n",
            "\n",
            "    accuracy                           0.66      6216\n",
            "   macro avg       0.63      0.62      0.62      6216\n",
            "weighted avg       0.65      0.66      0.65      6216\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# race categories\n",
        "print(\"\\nASIAN\")\n",
        "evaluate_subgroup('RACE_Asian', 1)\n",
        "print(\"\\nBLACK/AFRICAN AMERICAN\")\n",
        "evaluate_subgroup('RACE_Black/African American', 1)\n",
        "print(\"\\nHISPANIC/LATINO\")\n",
        "evaluate_subgroup('RACE_Hispanic/Latino', 1)\n",
        "print(\"\\nOTHER RACE\")\n",
        "evaluate_subgroup('RACE_Other', 1)\n",
        "print(\"\\nWHITE\")\n",
        "evaluate_subgroup('RACE_White', 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIVK9Ilqm9OT",
        "outputId": "6448ddd5-cded-40d2-f7e0-4037527694d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AGE 18-24\n",
            "Accuracy for age_18-24=1: 0.7553191489361702\n",
            "Confusion Matrix for age_18-24=1:\n",
            "[[ 12  37]\n",
            " [  9 130]]\n",
            "Classification Report for age_18-24=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.24      0.34        49\n",
            "           1       0.78      0.94      0.85       139\n",
            "\n",
            "    accuracy                           0.76       188\n",
            "   macro avg       0.67      0.59      0.60       188\n",
            "weighted avg       0.72      0.76      0.72       188\n",
            "\n",
            "\n",
            "AGE 25-44\n",
            "Accuracy for age_25-44=1: 0.6805555555555556\n",
            "Confusion Matrix for age_25-44=1:\n",
            "[[ 88 190]\n",
            " [ 86 500]]\n",
            "Classification Report for age_25-44=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.32      0.39       278\n",
            "           1       0.72      0.85      0.78       586\n",
            "\n",
            "    accuracy                           0.68       864\n",
            "   macro avg       0.62      0.58      0.59       864\n",
            "weighted avg       0.65      0.68      0.66       864\n",
            "\n",
            "\n",
            "AGE 45-64\n",
            "Accuracy for age_45-64=1: 0.6792649098474342\n",
            "Confusion Matrix for age_45-64=1:\n",
            "[[ 442  592]\n",
            " [ 333 1517]]\n",
            "Classification Report for age_45-64=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.43      0.49      1034\n",
            "           1       0.72      0.82      0.77      1850\n",
            "\n",
            "    accuracy                           0.68      2884\n",
            "   macro avg       0.64      0.62      0.63      2884\n",
            "weighted avg       0.67      0.68      0.67      2884\n",
            "\n",
            "\n",
            "AGE 65-88\n",
            "Accuracy for age_65-88=1: 0.6504513540621866\n",
            "Confusion Matrix for age_65-88=1:\n",
            "[[ 714  848]\n",
            " [ 546 1880]]\n",
            "Classification Report for age_65-88=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.46      0.51      1562\n",
            "           1       0.69      0.77      0.73      2426\n",
            "\n",
            "    accuracy                           0.65      3988\n",
            "   macro avg       0.63      0.62      0.62      3988\n",
            "weighted avg       0.64      0.65      0.64      3988\n",
            "\n",
            "\n",
            "AGE 89+\n",
            "Accuracy for age_89+=1: 0.6295264623955432\n",
            "Confusion Matrix for age_89+=1:\n",
            "[[ 52  69]\n",
            " [ 64 174]]\n",
            "Classification Report for age_89+=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.43      0.44       121\n",
            "           1       0.72      0.73      0.72       238\n",
            "\n",
            "    accuracy                           0.63       359\n",
            "   macro avg       0.58      0.58      0.58       359\n",
            "weighted avg       0.63      0.63      0.63       359\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#  age groups\n",
        "print(\"\\nAGE 18-24\")\n",
        "evaluate_subgroup('age_18-24', 1)\n",
        "print(\"\\nAGE 25-44\")\n",
        "evaluate_subgroup('age_25-44', 1)\n",
        "print(\"\\nAGE 45-64\")\n",
        "evaluate_subgroup('age_45-64', 1)\n",
        "print(\"\\nAGE 65-88\")\n",
        "evaluate_subgroup('age_65-88', 1)\n",
        "print(\"\\nAGE 89+\")\n",
        "evaluate_subgroup('age_89+', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIWiVLhHm9OT",
        "outputId": "72db9344-3e67-48f2-e975-0d1e73260d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MEDICAID\n",
            "Accuracy for INS_Medicaid=1: 0.6798029556650246\n",
            "Confusion Matrix for INS_Medicaid=1:\n",
            "[[ 70 145]\n",
            " [ 50 344]]\n",
            "Classification Report for INS_Medicaid=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.33      0.42       215\n",
            "           1       0.70      0.87      0.78       394\n",
            "\n",
            "    accuracy                           0.68       609\n",
            "   macro avg       0.64      0.60      0.60       609\n",
            "weighted avg       0.66      0.68      0.65       609\n",
            "\n",
            "\n",
            "MEDICARE\n",
            "Accuracy for INS_Medicare=1: 0.6428017575600931\n",
            "Confusion Matrix for INS_Medicare=1:\n",
            "[[ 692  802]\n",
            " [ 580 1795]]\n",
            "Classification Report for INS_Medicare=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.46      0.50      1494\n",
            "           1       0.69      0.76      0.72      2375\n",
            "\n",
            "    accuracy                           0.64      3869\n",
            "   macro avg       0.62      0.61      0.61      3869\n",
            "weighted avg       0.63      0.64      0.64      3869\n",
            "\n",
            "\n",
            "OTHER INSURANCE\n",
            "Accuracy for INS_Other=1: 0.6854139290407358\n",
            "Confusion Matrix for INS_Other=1:\n",
            "[[ 546  789]\n",
            " [ 408 2062]]\n",
            "Classification Report for INS_Other=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.48      1335\n",
            "           1       0.72      0.83      0.78      2470\n",
            "\n",
            "    accuracy                           0.69      3805\n",
            "   macro avg       0.65      0.62      0.63      3805\n",
            "weighted avg       0.67      0.69      0.67      3805\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# insurance types\n",
        "print(\"\\nMEDICAID\")\n",
        "evaluate_subgroup('INS_Medicaid', 1)\n",
        "print(\"\\nMEDICARE\")\n",
        "evaluate_subgroup('INS_Medicare', 1)\n",
        "print(\"\\nOTHER INSURANCE\")\n",
        "evaluate_subgroup('INS_Other', 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KmiEAV_EL4H"
      },
      "source": [
        "# Model with exclusion of protected attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LV-iF4SEL4H"
      },
      "outputs": [],
      "source": [
        "protected_attributes = ['gender', 'RACE_Asian', 'RACE_Black/African American',\n",
        "                 'RACE_Hispanic/Latino', 'RACE_Other', 'RACE_White', 'age_18-24',\n",
        "                 'age_25-44', 'age_45-64', 'age_65-88', 'age_89+', 'INS_Medicaid', 'INS_Medicare', 'INS_Other']\n",
        "\n",
        "featuresNew = [feat for feat in features if feat not in protected_attributes]\n",
        "\n",
        "X_without_protected = df[featuresNew]\n",
        "y = df['los_category']\n",
        "\n",
        "X_train_np, X_test_np, y_train, y_test = train_test_split(X_without_protected, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled_np, y_train_resampled = smote.fit_resample(X_train_np, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bq0d8AzEL4H",
        "outputId": "729c3c3f-0683-41af-e380-b6a0978c7b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Accuracy of XGBoost Classifier without protected attributes: 0.6595436436073886\n",
            "Overall Confusion Matrix without protected attributes:\n",
            "[[1420 1624]\n",
            " [1196 4043]]\n",
            "Overall Classification Report without protected attributes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.47      0.50      3044\n",
            "           1       0.71      0.77      0.74      5239\n",
            "\n",
            "    accuracy                           0.66      8283\n",
            "   macro avg       0.63      0.62      0.62      8283\n",
            "weighted avg       0.65      0.66      0.65      8283\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_rf_model.fit(X_train_resampled_np, y_train_resampled)\n",
        "y_pred_rf_np = best_rf_model.predict(X_test_np)\n",
        "\n",
        "accuracy_np = accuracy_score(y_test, y_pred_rf_np)\n",
        "print(\"Overall Accuracy of XGBoost Classifier without protected attributes:\", accuracy_np)\n",
        "\n",
        "conf_matrix_np = confusion_matrix(y_test, y_pred_rf_np)\n",
        "print(\"Overall Confusion Matrix without protected attributes:\")\n",
        "print(conf_matrix_np)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_encoded)\n",
        "\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_rf_np)\n",
        "\n",
        "class_report_labels = classification_report(y_test_labels, y_pred_labels)\n",
        "print(\"Overall Classification Report without protected attributes:\")\n",
        "print(class_report_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqWBy0b_EL4H",
        "outputId": "697a4e96-8ba3-4be5-97f8-eb37c2690093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics for gender = Female:\n",
            "Overall Accuracy: 0.6627140974967062\n",
            "Confusion Matrix:\n",
            "[[ 798  889]\n",
            " [ 647 2220]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.47      0.51      1687\n",
            "           1       0.71      0.77      0.74      2867\n",
            "\n",
            "    accuracy                           0.66      4554\n",
            "   macro avg       0.63      0.62      0.63      4554\n",
            "weighted avg       0.65      0.66      0.66      4554\n",
            "\n",
            "\n",
            "\n",
            "Metrics for gender = Male:\n",
            "Overall Accuracy: 0.6556717618664522\n",
            "Confusion Matrix:\n",
            "[[ 622  735]\n",
            " [ 549 1823]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.46      0.49      1357\n",
            "           1       0.71      0.77      0.74      2372\n",
            "\n",
            "    accuracy                           0.66      3729\n",
            "   macro avg       0.62      0.61      0.62      3729\n",
            "weighted avg       0.65      0.66      0.65      3729\n",
            "\n",
            "\n",
            "\n",
            "Metrics for RACE_Asian = 1:\n",
            "Overall Accuracy: 0.6877192982456141\n",
            "Confusion Matrix:\n",
            "[[ 42  65]\n",
            " [ 24 154]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.39      0.49       107\n",
            "           1       0.70      0.87      0.78       178\n",
            "\n",
            "    accuracy                           0.69       285\n",
            "   macro avg       0.67      0.63      0.63       285\n",
            "weighted avg       0.68      0.69      0.67       285\n",
            "\n",
            "\n",
            "\n",
            "Metrics for RACE_Black/African American = 1:\n",
            "Overall Accuracy: 0.6741116751269035\n",
            "Confusion Matrix:\n",
            "[[160 185]\n",
            " [136 504]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.46      0.50       345\n",
            "           1       0.73      0.79      0.76       640\n",
            "\n",
            "    accuracy                           0.67       985\n",
            "   macro avg       0.64      0.63      0.63       985\n",
            "weighted avg       0.66      0.67      0.67       985\n",
            "\n",
            "\n",
            "\n",
            "Metrics for RACE_Hispanic/Latino = 1:\n",
            "Overall Accuracy: 0.6621621621621622\n",
            "Confusion Matrix:\n",
            "[[ 57  83]\n",
            " [ 42 188]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.41      0.48       140\n",
            "           1       0.69      0.82      0.75       230\n",
            "\n",
            "    accuracy                           0.66       370\n",
            "   macro avg       0.63      0.61      0.61       370\n",
            "weighted avg       0.65      0.66      0.65       370\n",
            "\n",
            "\n",
            "\n",
            "Metrics for RACE_Other = 1:\n",
            "Overall Accuracy: 0.6651053864168618\n",
            "Confusion Matrix:\n",
            "[[ 53  88]\n",
            " [ 55 231]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.38      0.43       141\n",
            "           1       0.72      0.81      0.76       286\n",
            "\n",
            "    accuracy                           0.67       427\n",
            "   macro avg       0.61      0.59      0.59       427\n",
            "weighted avg       0.65      0.67      0.65       427\n",
            "\n",
            "\n",
            "\n",
            "Metrics for RACE_White = 1:\n",
            "Overall Accuracy: 0.6554054054054054\n",
            "Confusion Matrix:\n",
            "[[1108 1203]\n",
            " [ 939 2966]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.48      0.51      2311\n",
            "           1       0.71      0.76      0.73      3905\n",
            "\n",
            "    accuracy                           0.66      6216\n",
            "   macro avg       0.63      0.62      0.62      6216\n",
            "weighted avg       0.65      0.66      0.65      6216\n",
            "\n",
            "\n",
            "\n",
            "Metrics for age_18-24 = 1:\n",
            "Overall Accuracy: 0.7553191489361702\n",
            "Confusion Matrix:\n",
            "[[ 12  37]\n",
            " [  9 130]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.24      0.34        49\n",
            "           1       0.78      0.94      0.85       139\n",
            "\n",
            "    accuracy                           0.76       188\n",
            "   macro avg       0.67      0.59      0.60       188\n",
            "weighted avg       0.72      0.76      0.72       188\n",
            "\n",
            "\n",
            "\n",
            "Metrics for age_25-44 = 1:\n",
            "Overall Accuracy: 0.6886574074074074\n",
            "Confusion Matrix:\n",
            "[[ 90 188]\n",
            " [ 81 505]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.32      0.40       278\n",
            "           1       0.73      0.86      0.79       586\n",
            "\n",
            "    accuracy                           0.69       864\n",
            "   macro avg       0.63      0.59      0.60       864\n",
            "weighted avg       0.66      0.69      0.66       864\n",
            "\n",
            "\n",
            "\n",
            "Metrics for age_45-64 = 1:\n",
            "Overall Accuracy: 0.676490984743412\n",
            "Confusion Matrix:\n",
            "[[ 479  555]\n",
            " [ 378 1472]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.46      0.51      1034\n",
            "           1       0.73      0.80      0.76      1850\n",
            "\n",
            "    accuracy                           0.68      2884\n",
            "   macro avg       0.64      0.63      0.63      2884\n",
            "weighted avg       0.67      0.68      0.67      2884\n",
            "\n",
            "\n",
            "\n",
            "Metrics for age_65-88 = 1:\n",
            "Overall Accuracy: 0.6401705115346038\n",
            "Confusion Matrix:\n",
            "[[ 781  781]\n",
            " [ 654 1772]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.50      0.52      1562\n",
            "           1       0.69      0.73      0.71      2426\n",
            "\n",
            "    accuracy                           0.64      3988\n",
            "   macro avg       0.62      0.62      0.62      3988\n",
            "weighted avg       0.64      0.64      0.64      3988\n",
            "\n",
            "\n",
            "\n",
            "Metrics for age_89+ = 1:\n",
            "Overall Accuracy: 0.6183844011142061\n",
            "Confusion Matrix:\n",
            "[[ 58  63]\n",
            " [ 74 164]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.48      0.46       121\n",
            "           1       0.72      0.69      0.71       238\n",
            "\n",
            "    accuracy                           0.62       359\n",
            "   macro avg       0.58      0.58      0.58       359\n",
            "weighted avg       0.63      0.62      0.62       359\n",
            "\n",
            "\n",
            "\n",
            "Metrics for INS_Medicaid = 1:\n",
            "Overall Accuracy: 0.6896551724137931\n",
            "Confusion Matrix:\n",
            "[[ 81 134]\n",
            " [ 55 339]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.38      0.46       215\n",
            "           1       0.72      0.86      0.78       394\n",
            "\n",
            "    accuracy                           0.69       609\n",
            "   macro avg       0.66      0.62      0.62       609\n",
            "weighted avg       0.67      0.69      0.67       609\n",
            "\n",
            "\n",
            "\n",
            "Metrics for INS_Medicare = 1:\n",
            "Overall Accuracy: 0.6342724218144223\n",
            "Confusion Matrix:\n",
            "[[ 772  722]\n",
            " [ 693 1682]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.52      0.52      1494\n",
            "           1       0.70      0.71      0.70      2375\n",
            "\n",
            "    accuracy                           0.63      3869\n",
            "   macro avg       0.61      0.61      0.61      3869\n",
            "weighted avg       0.63      0.63      0.63      3869\n",
            "\n",
            "\n",
            "\n",
            "Metrics for INS_Other = 1:\n",
            "Overall Accuracy: 0.6804204993429698\n",
            "Confusion Matrix:\n",
            "[[ 567  768]\n",
            " [ 448 2022]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.42      0.48      1335\n",
            "           1       0.72      0.82      0.77      2470\n",
            "\n",
            "    accuracy                           0.68      3805\n",
            "   macro avg       0.64      0.62      0.63      3805\n",
            "weighted avg       0.67      0.68      0.67      3805\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# calculating metrics per protected attribute\n",
        "def calculate_protected_attribute_metrics(results, protected_attribute):\n",
        "    if protected_attribute == 'gender':\n",
        "        unique_values = results[protected_attribute].unique()\n",
        "        for value in unique_values:\n",
        "            subset = results[results[protected_attribute] == value]\n",
        "            y_test_subset = subset['y_test']\n",
        "            y_pred_subset = subset['y_pred']\n",
        "\n",
        "            accuracy = accuracy_score(y_test_subset, y_pred_subset)\n",
        "            conf_matrix = confusion_matrix(y_test_subset, y_pred_subset)\n",
        "\n",
        "            y_test_labels = label_encoder.inverse_transform(y_test_subset)\n",
        "            y_pred_labels = label_encoder.inverse_transform(y_pred_subset)\n",
        "            class_report = classification_report(y_test_labels, y_pred_labels)\n",
        "\n",
        "            gender_label = 'Female' if value == 1 else 'Male'\n",
        "            print(f\"Metrics for {protected_attribute} = {gender_label}:\")\n",
        "            print(f\"Overall Accuracy: {accuracy}\")\n",
        "            print(\"Confusion Matrix:\")\n",
        "            print(conf_matrix)\n",
        "            print(\"Classification Report:\")\n",
        "            print(class_report)\n",
        "            print(\"\\n\")\n",
        "    else:\n",
        "        unique_values = results[protected_attribute].unique()\n",
        "        for value in unique_values:\n",
        "          if value == 1:\n",
        "            subset = results[results[protected_attribute] == value]\n",
        "            y_test_subset = subset['y_test']\n",
        "            y_pred_subset = subset['y_pred']\n",
        "\n",
        "            accuracy = accuracy_score(y_test_subset, y_pred_subset)\n",
        "            conf_matrix = confusion_matrix(y_test_subset, y_pred_subset)\n",
        "\n",
        "            y_test_labels = label_encoder.inverse_transform(y_test_subset)\n",
        "            y_pred_labels = label_encoder.inverse_transform(y_pred_subset)\n",
        "            class_report = classification_report(y_test_labels, y_pred_labels)\n",
        "\n",
        "            print(f\"Metrics for {protected_attribute} = {value}:\")\n",
        "            print(f\"Overall Accuracy: {accuracy}\")\n",
        "            print(\"Confusion Matrix:\")\n",
        "            print(conf_matrix)\n",
        "            print(\"Classification Report:\")\n",
        "            print(class_report)\n",
        "            print(\"\\n\")\n",
        "\n",
        "X_test_with_protected = df.loc[X_test_np.index][protected_attributes].reset_index(drop=True)\n",
        "results = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred_rf_np})\n",
        "results = results.join(X_test_with_protected)\n",
        "\n",
        "for protected_attribute in protected_attributes:\n",
        "    calculate_protected_attribute_metrics(results, protected_attribute)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A2vmkXOpCPj"
      },
      "source": [
        "# Bias Mitigation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing"
      ],
      "metadata": {
        "id": "8W3a47sFy1OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXisEcMApF7r"
      },
      "source": [
        "# Pre-processing Technique: weighting\n",
        "\n",
        "Code inspo from: https://github.com/Trusted-AI/AIF360/blob/main/examples/demo_reweighing_preproc.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpzjHjBjpJ4B"
      },
      "outputs": [],
      "source": [
        "train_features = ['previous_stays', 'prev_los_avg', 'Anion Gap',\n",
        "                  'Bicarbonate', 'Chloride', 'Creatinine', 'Glucose', 'Hematocrit',\n",
        "                  'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Platelet Count',\n",
        "                  'Potassium', 'RDW', 'Red Blood Cells', 'Sodium', 'Urea Nitrogen',\n",
        "                  'White Blood Cells', 'prescrip_count', 'diagnoses_num',\n",
        "                  'ADM_Emergency', 'ADM_Other', 'ADM_Referral', 'ADM_Transfer',\n",
        "                  'gender', 'RACE_Asian', 'RACE_Black/African American',\n",
        "                  'RACE_Hispanic/Latino', 'RACE_Other', 'RACE_White', 'age_18-24',\n",
        "                  'age_25-44', 'age_45-64', 'age_65-88', 'age_89+', 'INS_Medicaid', 'INS_Medicare', 'INS_Other']\n",
        "\n",
        "# protected attributes\n",
        "protected_attributes = ['gender', 'RACE_Asian', 'RACE_Black/African American',\n",
        "                        'RACE_Hispanic/Latino', 'RACE_Other', 'RACE_White', 'age_18-24',\n",
        "                        'age_25-44', 'age_45-64', 'age_65-88', 'age_89+', 'INS_Medicaid', 'INS_Medicare', 'INS_Other']\n",
        "\n",
        "unprivileged_groups = [{'RACE_Other': 1}, {'RACE_Black/African American': 1},\n",
        "                       {'age_18-24': 1}, {'age_25-44': 1}, {'age_89+': 1},\n",
        "                       {'INS_Medicare': 1}, {'INS_Other': 1} ]\n",
        "\n",
        "\n",
        "privileged_groups = [{'RACE_White': 1}, {'RACE_Hispanic/Latino': 1}, {'RACE_Asian': 1},\n",
        "                     {'age_45-64': 1}, {'age_65-88': 1},\n",
        "                     {'INS_Medicaid': 1}]\n",
        "\n",
        "\n",
        "df['los_category'] = df_train['los_category'].map({'long': 0, 'short': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UALC8wyGpNki"
      },
      "outputs": [],
      "source": [
        "X = df[train_features]\n",
        "y = df['los_category']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Converting the training set into a BinaryLabelDataset\n",
        "df_train = X_train.copy()\n",
        "df_train['los_category'] = y_train\n",
        "\n",
        "\n",
        "binary_label_dataset_train = BinaryLabelDataset(\n",
        "    df=df_train,\n",
        "    label_names=['los_category'],\n",
        "    protected_attribute_names=protected_attributes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0HSiI37pe5-"
      },
      "outputs": [],
      "source": [
        "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "\n",
        "# reweighing on training set\n",
        "train_rw = RW.fit_transform(binary_label_dataset_train)\n",
        "\n",
        "df_train_rw = train_rw.convert_to_dataframe()[0]\n",
        "X_train_rw = df_train_rw[train_features]\n",
        "y_train_rw = df_train_rw['los_category']\n",
        "\n",
        "# SMOTE for 'los' imbalance in reweighted training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_rw, y_train_rw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "L_m-P9f7pQCm",
        "outputId": "8bb16098-49bb-4347-dce8-884dbbb03b3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'max_depth': 9, 'max_features': 0.6, 'n_estimators': 100}\n",
            "Overall Accuracy of Random Forest Classifier: 0.6672703126886393\n",
            "Overall Confusion Matrix:\n",
            "[[1270 1774]\n",
            " [ 982 4257]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_encoded' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6cc8d9230c75>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0my_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_encoded' is not defined"
          ]
        }
      ],
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_features': [0.6, 0.7, 0.8]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred_rf = best_rf_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Overall Accuracy of Random Forest Classifier:\", accuracy)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
        "print(\"Overall Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_encoded)\n",
        "\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_rf)\n",
        "\n",
        "class_report_labels = classification_report(y_test_labels, y_pred_labels)\n",
        "print(\"Overall Classification Report:\")\n",
        "print(class_report_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_report_labels = classification_report(y_test, y_pred_rf)\n",
        "print(\"Overall Classification Report:\")\n",
        "print(class_report_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvRMuXOET6ga",
        "outputId": "ccbdc3ed-aedb-4203-c5c9-947c01b4a6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.42      0.48      3044\n",
            "           1       0.71      0.81      0.76      5239\n",
            "\n",
            "    accuracy                           0.67      8283\n",
            "   macro avg       0.63      0.61      0.62      8283\n",
            "weighted avg       0.65      0.67      0.65      8283\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_subgroup(subgroup_name, subgroup_value):\n",
        "    subgroup_indices = X_test[subgroup_name] == subgroup_value\n",
        "    subgroup_X_test = X_test[subgroup_indices]\n",
        "    subgroup_y_test = y_test[subgroup_indices]\n",
        "    subgroup_y_pred = y_pred_rf[subgroup_indices]\n",
        "\n",
        "    accuracy = accuracy_score(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Accuracy for {subgroup_name}={subgroup_value}: {accuracy}\")\n",
        "\n",
        "    conf_matrix = confusion_matrix(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Confusion Matrix for {subgroup_name}={subgroup_value}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    class_report = classification_report(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Classification Report for {subgroup_name}={subgroup_value}:\")\n",
        "    print(class_report)\n",
        "\n",
        "print(\"\\nASIAN\")\n",
        "evaluate_subgroup('RACE_Asian', 1)\n",
        "print(\"\\nBLACK/AFRICAN AMERICAN\")\n",
        "evaluate_subgroup('RACE_Black/African American', 1)\n",
        "print(\"\\nHISPANIC/LATINO\")\n",
        "evaluate_subgroup('RACE_Hispanic/Latino', 1)\n",
        "print(\"\\nOTHER RACE\")\n",
        "evaluate_subgroup('RACE_Other', 1)\n",
        "print(\"\\nWHITE\")\n",
        "evaluate_subgroup('RACE_White', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhpOpvBugK5E",
        "outputId": "aa6c7053-a501-4560-c407-808eb5d35b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ASIAN\n",
            "Accuracy for RACE_Asian=1: 0.6982456140350877\n",
            "Confusion Matrix for RACE_Asian=1:\n",
            "[[ 37  70]\n",
            " [ 16 162]]\n",
            "Classification Report for RACE_Asian=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.35      0.46       107\n",
            "           1       0.70      0.91      0.79       178\n",
            "\n",
            "    accuracy                           0.70       285\n",
            "   macro avg       0.70      0.63      0.63       285\n",
            "weighted avg       0.70      0.70      0.67       285\n",
            "\n",
            "\n",
            "BLACK/AFRICAN AMERICAN\n",
            "Accuracy for RACE_Black/African American=1: 0.6862944162436548\n",
            "Confusion Matrix for RACE_Black/African American=1:\n",
            "[[135 210]\n",
            " [ 99 541]]\n",
            "Classification Report for RACE_Black/African American=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.39      0.47       345\n",
            "           1       0.72      0.85      0.78       640\n",
            "\n",
            "    accuracy                           0.69       985\n",
            "   macro avg       0.65      0.62      0.62       985\n",
            "weighted avg       0.67      0.69      0.67       985\n",
            "\n",
            "\n",
            "HISPANIC/LATINO\n",
            "Accuracy for RACE_Hispanic/Latino=1: 0.6675675675675675\n",
            "Confusion Matrix for RACE_Hispanic/Latino=1:\n",
            "[[ 50  90]\n",
            " [ 33 197]]\n",
            "Classification Report for RACE_Hispanic/Latino=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.36      0.45       140\n",
            "           1       0.69      0.86      0.76       230\n",
            "\n",
            "    accuracy                           0.67       370\n",
            "   macro avg       0.64      0.61      0.61       370\n",
            "weighted avg       0.65      0.67      0.64       370\n",
            "\n",
            "\n",
            "OTHER RACE\n",
            "Accuracy for RACE_Other=1: 0.6744730679156908\n",
            "Confusion Matrix for RACE_Other=1:\n",
            "[[ 41 100]\n",
            " [ 39 247]]\n",
            "Classification Report for RACE_Other=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.29      0.37       141\n",
            "           1       0.71      0.86      0.78       286\n",
            "\n",
            "    accuracy                           0.67       427\n",
            "   macro avg       0.61      0.58      0.58       427\n",
            "weighted avg       0.65      0.67      0.65       427\n",
            "\n",
            "\n",
            "WHITE\n",
            "Accuracy for RACE_White=1: 0.6623230373230373\n",
            "Confusion Matrix for RACE_White=1:\n",
            "[[1007 1304]\n",
            " [ 795 3110]]\n",
            "Classification Report for RACE_White=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.44      0.49      2311\n",
            "           1       0.70      0.80      0.75      3905\n",
            "\n",
            "    accuracy                           0.66      6216\n",
            "   macro avg       0.63      0.62      0.62      6216\n",
            "weighted avg       0.65      0.66      0.65      6216\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  age groups\n",
        "print(\"\\nAGE 18-24\")\n",
        "evaluate_subgroup('age_18-24', 1)\n",
        "print(\"\\nAGE 25-44\")\n",
        "evaluate_subgroup('age_25-44', 1)\n",
        "print(\"\\nAGE 45-64\")\n",
        "evaluate_subgroup('age_45-64', 1)\n",
        "print(\"\\nAGE 65-88\")\n",
        "evaluate_subgroup('age_65-88', 1)\n",
        "print(\"\\nAGE 89+\")\n",
        "evaluate_subgroup('age_89+', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve2NIh1NgSar",
        "outputId": "f4c6febe-aff3-4287-dbab-5d8333fbe09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AGE 18-24\n",
            "Accuracy for age_18-24=1: 0.7659574468085106\n",
            "Confusion Matrix for age_18-24=1:\n",
            "[[ 10  39]\n",
            " [  5 134]]\n",
            "Classification Report for age_18-24=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.20      0.31        49\n",
            "           1       0.77      0.96      0.86       139\n",
            "\n",
            "    accuracy                           0.77       188\n",
            "   macro avg       0.72      0.58      0.59       188\n",
            "weighted avg       0.75      0.77      0.72       188\n",
            "\n",
            "\n",
            "AGE 25-44\n",
            "Accuracy for age_25-44=1: 0.6967592592592593\n",
            "Confusion Matrix for age_25-44=1:\n",
            "[[ 85 193]\n",
            " [ 69 517]]\n",
            "Classification Report for age_25-44=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.31      0.39       278\n",
            "           1       0.73      0.88      0.80       586\n",
            "\n",
            "    accuracy                           0.70       864\n",
            "   macro avg       0.64      0.59      0.60       864\n",
            "weighted avg       0.67      0.70      0.67       864\n",
            "\n",
            "\n",
            "AGE 45-64\n",
            "Accuracy for age_45-64=1: 0.6778779472954231\n",
            "Confusion Matrix for age_45-64=1:\n",
            "[[ 427  607]\n",
            " [ 322 1528]]\n",
            "Classification Report for age_45-64=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.41      0.48      1034\n",
            "           1       0.72      0.83      0.77      1850\n",
            "\n",
            "    accuracy                           0.68      2884\n",
            "   macro avg       0.64      0.62      0.62      2884\n",
            "weighted avg       0.66      0.68      0.66      2884\n",
            "\n",
            "\n",
            "AGE 65-88\n",
            "Accuracy for age_65-88=1: 0.649949849548646\n",
            "Confusion Matrix for age_65-88=1:\n",
            "[[ 700  862]\n",
            " [ 534 1892]]\n",
            "Classification Report for age_65-88=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.45      0.50      1562\n",
            "           1       0.69      0.78      0.73      2426\n",
            "\n",
            "    accuracy                           0.65      3988\n",
            "   macro avg       0.63      0.61      0.62      3988\n",
            "weighted avg       0.64      0.65      0.64      3988\n",
            "\n",
            "\n",
            "AGE 89+\n",
            "Accuracy for age_89+=1: 0.6518105849582173\n",
            "Confusion Matrix for age_89+=1:\n",
            "[[ 48  73]\n",
            " [ 52 186]]\n",
            "Classification Report for age_89+=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.40      0.43       121\n",
            "           1       0.72      0.78      0.75       238\n",
            "\n",
            "    accuracy                           0.65       359\n",
            "   macro avg       0.60      0.59      0.59       359\n",
            "weighted avg       0.64      0.65      0.64       359\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insurance types\n",
        "print(\"\\nMEDICAID\")\n",
        "evaluate_subgroup('INS_Medicaid', 1)\n",
        "print(\"\\nMEDICARE\")\n",
        "evaluate_subgroup('INS_Medicare', 1)\n",
        "print(\"\\nOTHER INSURANCE\")\n",
        "evaluate_subgroup('INS_Other', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9FywzlLiXnl",
        "outputId": "e5fd8e41-d607-4212-b640-a05063300790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MEDICAID\n",
            "Accuracy for INS_Medicaid=1: 0.7110016420361248\n",
            "Confusion Matrix for INS_Medicaid=1:\n",
            "[[ 77 138]\n",
            " [ 38 356]]\n",
            "Classification Report for INS_Medicaid=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.36      0.47       215\n",
            "           1       0.72      0.90      0.80       394\n",
            "\n",
            "    accuracy                           0.71       609\n",
            "   macro avg       0.70      0.63      0.63       609\n",
            "weighted avg       0.70      0.71      0.68       609\n",
            "\n",
            "\n",
            "MEDICARE\n",
            "Accuracy for INS_Medicare=1: 0.6461617989144481\n",
            "Confusion Matrix for INS_Medicare=1:\n",
            "[[ 677  817]\n",
            " [ 552 1823]]\n",
            "Classification Report for INS_Medicare=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.45      0.50      1494\n",
            "           1       0.69      0.77      0.73      2375\n",
            "\n",
            "    accuracy                           0.65      3869\n",
            "   macro avg       0.62      0.61      0.61      3869\n",
            "weighted avg       0.64      0.65      0.64      3869\n",
            "\n",
            "\n",
            "OTHER INSURANCE\n",
            "Accuracy for INS_Other=1: 0.6817345597897503\n",
            "Confusion Matrix for INS_Other=1:\n",
            "[[ 516  819]\n",
            " [ 392 2078]]\n",
            "Classification Report for INS_Other=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.39      0.46      1335\n",
            "           1       0.72      0.84      0.77      2470\n",
            "\n",
            "    accuracy                           0.68      3805\n",
            "   macro avg       0.64      0.61      0.62      3805\n",
            "weighted avg       0.67      0.68      0.66      3805\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exp gradient: in-processing\n"
      ],
      "metadata": {
        "id": "PaHte0ZUf_au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from fairlearn.reductions import ExponentiatedGradient, DemographicParity"
      ],
      "metadata": {
        "id": "YZQYh9qUhH-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = ['previous_stays', 'prev_los_avg', 'Anion Gap',\n",
        "                  'Bicarbonate', 'Chloride', 'Creatinine', 'Glucose', 'Hematocrit',\n",
        "                  'Hemoglobin', 'MCH', 'MCHC', 'MCV', 'Magnesium', 'Platelet Count',\n",
        "                  'Potassium', 'RDW', 'Red Blood Cells', 'Sodium', 'Urea Nitrogen',\n",
        "                  'White Blood Cells', 'prescrip_count', 'diagnoses_num',\n",
        "                  'ADM_Emergency', 'ADM_Other', 'ADM_Referral', 'ADM_Transfer',\n",
        "                  'gender', 'RACE_Asian', 'RACE_Black/African American',\n",
        "                  'RACE_Hispanic/Latino', 'RACE_Other', 'RACE_White', 'age_18-24',\n",
        "                  'age_25-44', 'age_45-64', 'age_65-88', 'age_89+', 'INS_Medicaid', 'INS_Medicare', 'INS_Other']\n",
        "\n",
        "protected_attributes = ['RACE_Asian', 'RACE_Black/African American',\n",
        "                        'RACE_Hispanic/Latino', 'RACE_Other', 'RACE_White', 'age_18-24',\n",
        "                        'age_25-44', 'age_45-64', 'age_65-88', 'age_89+', 'INS_Medicaid', 'INS_Medicare', 'INS_Other']"
      ],
      "metadata": {
        "id": "BiQ2bJ4Uiwnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[train_features]\n",
        "y = df['los_category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "r_074h0fizVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_resampled = pd.concat([X_train_resampled], axis=1)\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    max_depth=9,\n",
        "    max_features=0.6,\n",
        "    n_estimators=100\n",
        ")\n",
        "\n",
        "# Fairness constraint: Demographic Parity\n",
        "constraint = DemographicParity()\n",
        "\n",
        "mitigator = ExponentiatedGradient(estimator=rf_model, constraints=constraint)\n",
        "mitigator.fit(X_train_resampled, y_train_resampled, sensitive_features=X_train_resampled[protected_attributes])\n",
        "\n",
        "y_pred = mitigator.predict(X_test)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNtyvfdii9IB",
        "outputId": "49304281-6030-439d-d458-c0b4e5d33ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:212: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.pos_basis[i] = 0 + zero_vec\n",
            "/usr/local/lib/python3.10/dist-packages/fairlearn/reductions/_moments/utility_parity.py:213: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self.neg_basis[i] = 0 + zero_vec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_report_labels = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Overall Classification Report:\")\n",
        "print(class_report_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQpsoGx_IpQ6",
        "outputId": "e81bb31e-3c45-47e6-eabb-63300fc9531e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.57      0.49      3044\n",
            "           1       0.69      0.56      0.62      5239\n",
            "\n",
            "    accuracy                           0.56      8283\n",
            "   macro avg       0.56      0.56      0.55      8283\n",
            "weighted avg       0.59      0.56      0.57      8283\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_subgroup(subgroup_name, subgroup_value):\n",
        "    subgroup_indices = X_test[subgroup_name] == subgroup_value\n",
        "    subgroup_X_test = X_test[subgroup_indices]\n",
        "    subgroup_y_test = y_test[subgroup_indices]\n",
        "    subgroup_y_pred = y_pred[subgroup_indices]\n",
        "\n",
        "    accuracy = accuracy_score(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Accuracy for {subgroup_name}={subgroup_value}: {accuracy}\")\n",
        "\n",
        "    conf_matrix = confusion_matrix(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Confusion Matrix for {subgroup_name}={subgroup_value}:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    class_report = classification_report(subgroup_y_test, subgroup_y_pred)\n",
        "    print(f\"Classification Report for {subgroup_name}={subgroup_value}:\")\n",
        "    print(class_report)\n",
        "\n",
        "print(\"\\nASIAN\")\n",
        "evaluate_subgroup('RACE_Asian', 1)\n",
        "print(\"\\nBLACK/AFRICAN AMERICAN\")\n",
        "evaluate_subgroup('RACE_Black/African American', 1)\n",
        "print(\"\\nHISPANIC/LATINO\")\n",
        "evaluate_subgroup('RACE_Hispanic/Latino', 1)\n",
        "print(\"\\nOTHER RACE\")\n",
        "evaluate_subgroup('RACE_Other', 1)\n",
        "print(\"\\nWHITE\")\n",
        "evaluate_subgroup('RACE_White', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK8in9_iJCuJ",
        "outputId": "0493affa-e840-4578-89ce-58537edaba5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ASIAN\n",
            "Accuracy for RACE_Asian=1: 0.5578947368421052\n",
            "Confusion Matrix for RACE_Asian=1:\n",
            "[[ 58  49]\n",
            " [ 77 101]]\n",
            "Classification Report for RACE_Asian=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.54      0.48       107\n",
            "           1       0.67      0.57      0.62       178\n",
            "\n",
            "    accuracy                           0.56       285\n",
            "   macro avg       0.55      0.55      0.55       285\n",
            "weighted avg       0.58      0.56      0.56       285\n",
            "\n",
            "\n",
            "BLACK/AFRICAN AMERICAN\n",
            "Accuracy for RACE_Black/African American=1: 0.5411167512690356\n",
            "Confusion Matrix for RACE_Black/African American=1:\n",
            "[[189 156]\n",
            " [296 344]]\n",
            "Classification Report for RACE_Black/African American=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.55      0.46       345\n",
            "           1       0.69      0.54      0.60       640\n",
            "\n",
            "    accuracy                           0.54       985\n",
            "   macro avg       0.54      0.54      0.53       985\n",
            "weighted avg       0.58      0.54      0.55       985\n",
            "\n",
            "\n",
            "HISPANIC/LATINO\n",
            "Accuracy for RACE_Hispanic/Latino=1: 0.5621621621621622\n",
            "Confusion Matrix for RACE_Hispanic/Latino=1:\n",
            "[[ 73  67]\n",
            " [ 95 135]]\n",
            "Classification Report for RACE_Hispanic/Latino=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.52      0.47       140\n",
            "           1       0.67      0.59      0.62       230\n",
            "\n",
            "    accuracy                           0.56       370\n",
            "   macro avg       0.55      0.55      0.55       370\n",
            "weighted avg       0.58      0.56      0.57       370\n",
            "\n",
            "\n",
            "OTHER RACE\n",
            "Accuracy for RACE_Other=1: 0.5175644028103045\n",
            "Confusion Matrix for RACE_Other=1:\n",
            "[[ 74  67]\n",
            " [139 147]]\n",
            "Classification Report for RACE_Other=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.52      0.42       141\n",
            "           1       0.69      0.51      0.59       286\n",
            "\n",
            "    accuracy                           0.52       427\n",
            "   macro avg       0.52      0.52      0.50       427\n",
            "weighted avg       0.57      0.52      0.53       427\n",
            "\n",
            "\n",
            "WHITE\n",
            "Accuracy for RACE_White=1: 0.5685328185328186\n",
            "Confusion Matrix for RACE_White=1:\n",
            "[[1338  973]\n",
            " [1709 2196]]\n",
            "Classification Report for RACE_White=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.58      0.50      2311\n",
            "           1       0.69      0.56      0.62      3905\n",
            "\n",
            "    accuracy                           0.57      6216\n",
            "   macro avg       0.57      0.57      0.56      6216\n",
            "weighted avg       0.60      0.57      0.58      6216\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  age groups\n",
        "print(\"\\nAGE 18-24\")\n",
        "evaluate_subgroup('age_18-24', 1)\n",
        "print(\"\\nAGE 25-44\")\n",
        "evaluate_subgroup('age_25-44', 1)\n",
        "print(\"\\nAGE 45-64\")\n",
        "evaluate_subgroup('age_45-64', 1)\n",
        "print(\"\\nAGE 65-88\")\n",
        "evaluate_subgroup('age_65-88', 1)\n",
        "print(\"\\nAGE 89+\")\n",
        "evaluate_subgroup('age_89+', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EaN2SCtJFsg",
        "outputId": "5d50a287-1fb5-4a33-c663-a6eeb645d714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AGE 18-24\n",
            "Accuracy for age_18-24=1: 0.5585106382978723\n",
            "Confusion Matrix for age_18-24=1:\n",
            "[[28 21]\n",
            " [62 77]]\n",
            "Classification Report for age_18-24=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.57      0.40        49\n",
            "           1       0.79      0.55      0.65       139\n",
            "\n",
            "    accuracy                           0.56       188\n",
            "   macro avg       0.55      0.56      0.53       188\n",
            "weighted avg       0.66      0.56      0.59       188\n",
            "\n",
            "\n",
            "AGE 25-44\n",
            "Accuracy for age_25-44=1: 0.5636574074074074\n",
            "Confusion Matrix for age_25-44=1:\n",
            "[[159 119]\n",
            " [258 328]]\n",
            "Classification Report for age_25-44=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.57      0.46       278\n",
            "           1       0.73      0.56      0.64       586\n",
            "\n",
            "    accuracy                           0.56       864\n",
            "   macro avg       0.56      0.57      0.55       864\n",
            "weighted avg       0.62      0.56      0.58       864\n",
            "\n",
            "\n",
            "AGE 45-64\n",
            "Accuracy for age_45-64=1: 0.5800970873786407\n",
            "Confusion Matrix for age_45-64=1:\n",
            "[[ 612  422]\n",
            " [ 789 1061]]\n",
            "Classification Report for age_45-64=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.59      0.50      1034\n",
            "           1       0.72      0.57      0.64      1850\n",
            "\n",
            "    accuracy                           0.58      2884\n",
            "   macro avg       0.58      0.58      0.57      2884\n",
            "weighted avg       0.62      0.58      0.59      2884\n",
            "\n",
            "\n",
            "AGE 65-88\n",
            "Accuracy for age_65-88=1: 0.552407221664995\n",
            "Confusion Matrix for age_65-88=1:\n",
            "[[ 871  691]\n",
            " [1094 1332]]\n",
            "Classification Report for age_65-88=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.56      0.49      1562\n",
            "           1       0.66      0.55      0.60      2426\n",
            "\n",
            "    accuracy                           0.55      3988\n",
            "   macro avg       0.55      0.55      0.55      3988\n",
            "weighted avg       0.57      0.55      0.56      3988\n",
            "\n",
            "\n",
            "AGE 89+\n",
            "Accuracy for age_89+=1: 0.520891364902507\n",
            "Confusion Matrix for age_89+=1:\n",
            "[[ 62  59]\n",
            " [113 125]]\n",
            "Classification Report for age_89+=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.51      0.42       121\n",
            "           1       0.68      0.53      0.59       238\n",
            "\n",
            "    accuracy                           0.52       359\n",
            "   macro avg       0.52      0.52      0.51       359\n",
            "weighted avg       0.57      0.52      0.53       359\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insurance types\n",
        "print(\"\\nMEDICAID\")\n",
        "evaluate_subgroup('INS_Medicaid', 1)\n",
        "print(\"\\nMEDICARE\")\n",
        "evaluate_subgroup('INS_Medicare', 1)\n",
        "print(\"\\nOTHER INSURANCE\")\n",
        "evaluate_subgroup('INS_Other', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-wq93ZRJL-h",
        "outputId": "c0b87a6b-5cac-4055-8676-dd9b1edb69be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MEDICAID\n",
            "Accuracy for INS_Medicaid=1: 0.5779967159277504\n",
            "Confusion Matrix for INS_Medicaid=1:\n",
            "[[123  92]\n",
            " [165 229]]\n",
            "Classification Report for INS_Medicaid=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.57      0.49       215\n",
            "           1       0.71      0.58      0.64       394\n",
            "\n",
            "    accuracy                           0.58       609\n",
            "   macro avg       0.57      0.58      0.56       609\n",
            "weighted avg       0.61      0.58      0.59       609\n",
            "\n",
            "\n",
            "MEDICARE\n",
            "Accuracy for INS_Medicare=1: 0.5482036701990178\n",
            "Confusion Matrix for INS_Medicare=1:\n",
            "[[ 850  644]\n",
            " [1104 1271]]\n",
            "Classification Report for INS_Medicare=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.57      0.49      1494\n",
            "           1       0.66      0.54      0.59      2375\n",
            "\n",
            "    accuracy                           0.55      3869\n",
            "   macro avg       0.55      0.55      0.54      3869\n",
            "weighted avg       0.58      0.55      0.55      3869\n",
            "\n",
            "\n",
            "OTHER INSURANCE\n",
            "Accuracy for INS_Other=1: 0.5734559789750329\n",
            "Confusion Matrix for INS_Other=1:\n",
            "[[ 759  576]\n",
            " [1047 1423]]\n",
            "Classification Report for INS_Other=1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.57      0.48      1335\n",
            "           1       0.71      0.58      0.64      2470\n",
            "\n",
            "    accuracy                           0.57      3805\n",
            "   macro avg       0.57      0.57      0.56      3805\n",
            "weighted avg       0.61      0.57      0.58      3805\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}